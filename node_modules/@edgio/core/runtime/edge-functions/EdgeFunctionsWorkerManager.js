"use strict";
var __importDefault = (this && this.__importDefault) || function (mod) {
    return (mod && mod.__esModule) ? mod : { "default": mod };
};
Object.defineProperty(exports, "__esModule", { value: true });
const path_1 = require("path");
const Worker_1 = require("./Worker");
const assert_1 = __importDefault(require("assert"));
const EdgeFunctionWorkerParams_1 = __importDefault(require("./EdgeFunctionWorkerParams"));
const node_fetch_1 = __importDefault(require("node-fetch"));
const EdgeFunctionResponse_1 = __importDefault(require("./EdgeFunctionResponse"));
const Serializer_1 = require("./Serializer");
const buffer_1 = require("buffer");
// The size of the exchange buffer used for exchanging the data between the main thread and the worker thread.
// Arbitrarily set to 50MB as assumed sufficient enough for most requests. If the size is exceeded, the worker
// will throw an error.
const EXCHANGE_BUFFER_SIZE = 50000000;
class EdgeFunctionsWorkerManager {
    constructor(context, rawBody, path, envVars, usrVars) {
        this.readyResponses = [];
        this.outstandingFetchesCount = 0;
        this.workerIsWaiting = false;
        this.context = context;
        this.semaphore = new Int32Array(new SharedArrayBuffer(Int32Array.BYTES_PER_ELEMENT * 1));
        this.exchangeBuffer = new SharedArrayBuffer(Int8Array.BYTES_PER_ELEMENT * EXCHANGE_BUFFER_SIZE);
        this.dataLength = new Int32Array(new SharedArrayBuffer(Int32Array.BYTES_PER_ELEMENT * 1));
        this.channel = new MessageChannel();
        const workerData = {
            semaphore: this.semaphore,
            exchangeBuffer: this.exchangeBuffer,
            exchangeBufferSize: EXCHANGE_BUFFER_SIZE,
            dataLength: this.dataLength,
            params: new EdgeFunctionWorkerParams_1.default(context.getRequest(), rawBody, path, envVars, usrVars, context.propertyContext.origins),
        };
        this.worker = new Worker_1.Worker((0, path_1.join)(__dirname, this.getWorkerFilename()));
        // Unlike NodeJS worker_threads, the web workers API in browser does not
        // support passing data to worker via options argument of the constructor.
        // Instead, we send workerData as a message named 'init' command.
        this.worker.postMessage({
            command: 'init',
            workerData,
        });
        Atomics.store(this.semaphore, 0, 0);
    }
    // We select the worker file based on the environment. The "./EdgeFunctionBrowserWorker.js" file is used in the browser.
    // Both files are generated from the same EdgeFunctionWorker.ts source file,
    // but the browser version is bigger and bundled with libraries that ensures compatibility.
    getWorkerFilename() {
        return typeof window === 'undefined'
            ? './EdgeFunctionWorker.js'
            : './EdgeFunctionBrowserWorker.js';
    }
    async runEdgeFunction() {
        return new Promise((resolve, reject) => {
            // Receives messages from the worker thread in a form of an array of arguments.
            // The first argument is always `type` of the message, with the rest of the arguments
            // being the actual message data, also sent as an array.
            // @ts-ignore
            this.channel.port2.onmessage = (event) => {
                var _a, _b, _c, _d;
                const message = event.data;
                const type = message.shift();
                switch (type) {
                    case 'done-response': {
                        const response = message.shift();
                        this.worker.terminate();
                        const edgeResponse = new EdgeFunctionResponse_1.default(response);
                        resolve(edgeResponse);
                        break;
                    }
                    case 'done-error': {
                        const error = message.shift();
                        this.worker.terminate();
                        // We reject with the error object (or whatever!) that we got from the worker thread
                        // so that we show its stack trace (which points to the actual point of failure) rather than
                        // mask it with manager's stack trace which will always be this handler and is thus useless.
                        reject(error);
                        break;
                    }
                    case 'done-exception': {
                        const panicString = message.shift();
                        this.worker.terminate();
                        reject(new Error(panicString));
                        break;
                    }
                    case 'error': {
                        const error = message.shift();
                        this.worker.terminate();
                        reject(new Error(error));
                        break;
                    }
                    case 'stdout': {
                        const buffer = message.shift();
                        (_b = (_a = this.context) === null || _a === void 0 ? void 0 : _a.stdout) === null || _b === void 0 ? void 0 : _b.write(buffer);
                        break;
                    }
                    case 'stderr': {
                        const buffer = message.shift();
                        (_d = (_c = this.context) === null || _c === void 0 ? void 0 : _c.stderr) === null || _d === void 0 ? void 0 : _d.write(buffer);
                        break;
                    }
                    case 'debug': {
                        // Ignore the debug messages as they are only relevant for internal troubleshooting.
                        // If you need to troubleshoot a problem, the writing the received message is easy.
                        // const buffer = message.shift()
                        // process.stdout.write(buffer)
                        break;
                    }
                    case 'fetch': {
                        const requestId = message.shift();
                        this.issueFetch(requestId, ...message);
                        break;
                    }
                    case 'waiting': {
                        // Signals to the main thread that the worker is waiting for a message.
                        // If any response is ready, send it to the worker immediately.
                        this.workerIsWaiting = true;
                        // If there are no pending responses and no outstanding fetches, then
                        // the worker has made a mistake and should not have waited. Instead
                        // of it waiting forever, we wake it up setting the response to error
                        // of our own.
                        if (this.readyResponses.length === 0 && this.outstandingFetchesCount === 0) {
                            this.addReadyResponse({
                                error: new Error('Bad wait: no outstanding fetches or pending responses'),
                            });
                            return;
                        }
                        if (this.readyResponses.length > 0) {
                            this.sendNextReadyResponse();
                            return;
                        }
                        break;
                    }
                    default:
                        throw new Error(`Unknown message type: ${type}`);
                }
            };
            this.worker.postMessage({
                command: 'run',
                port: this.channel.port1,
            }, [
                //@ts-ignore
                this.channel.port1,
            ]);
        });
    }
    /// Issues a fetch request that was serialized from the worker thread.
    async issueFetch(requestId, ...fetchArgs) {
        var _a;
        ++this.outstandingFetchesCount;
        // Sailfish does not follow redirects, so the CLI EdgeFunctions need to emulate that.
        // Our QuickJs implements redirect on top of this 'basic' Sailfish type of fetch.
        const [url, options] = fetchArgs;
        options.redirect = 'manual';
        // Update the URL based on fetch origin and local overrides
        let updatedUrl = new URL(url);
        if (options.fetchOrigin === undefined) {
            throw new Error('Fetch failed: request.fetchOrigin is undefined');
        }
        else {
            let fetchOrigin = options.fetchOrigin;
            if (fetchOrigin.override_host_header) {
                options.headers['host'] = fetchOrigin.override_host_header;
            }
            const hosts = fetchOrigin.hosts;
            if (hosts === undefined) {
                throw new Error('Fetch failed: request.fetchOrigin.hosts is undefined');
            }
            const randomHostIndex = Math.floor(Math.random() * hosts.length);
            const randomHost = hosts[randomHostIndex];
            // OriginBackends.location is either a:
            // * Single Hostname string
            // * Array of Hostname string
            // * Array of object with {Port, Hostname}
            // If we get an array, we choose a random one from it.
            let location = randomHost.location;
            if (location === undefined) {
                throw new Error(`Fetch failed: request.fetchOrigin.hosts[${randomHostIndex}].location is undefined`);
            }
            if (typeof location === 'string') {
                updatedUrl.hostname = location;
            }
            else if (Array.isArray(location)) {
                // Pick a random location from the array.
                const randomLocation = location[Math.floor(Math.random() * location.length)];
                if (typeof randomLocation === 'string') {
                    updatedUrl.hostname = randomLocation;
                }
                else if (typeof randomLocation === 'object') {
                    updatedUrl.hostname = randomLocation.hostname;
                    if (randomLocation.port) {
                        updatedUrl.port = randomLocation.port.toString();
                    }
                }
            }
            // This environment variable allows us to override the upstream host so we can test edge functions
            // against a local web server.
            const upstreamOverride = (_a = process === null || process === void 0 ? void 0 : process.env) === null || _a === void 0 ? void 0 : _a['EDGIO_CLI_UPSTREAM_OVERRIDE'];
            if (upstreamOverride) {
                const upstreamOverrideUrl = new URL(upstreamOverride);
                updatedUrl.protocol = upstreamOverrideUrl.protocol;
                updatedUrl.hostname = upstreamOverrideUrl.hostname;
                updatedUrl.port = upstreamOverrideUrl.port;
                console.warn(`Overriding upstream ${url} with ${updatedUrl} from EDGIO_CLI_UPSTREAM_OVERRIDE`);
            }
        }
        EdgeFunctionsWorkerManager.fetchImpl(updatedUrl.toString(), options)
            .then(async (response) => {
            const body = await response.buffer();
            --this.outstandingFetchesCount;
            // Now that the body has been decoded, remove the content-encoding header,
            // as it is no longer valid. Edge functions always work with decoded content
            // and fetch doesn't even allow access to encoded content but unfortunately
            // leaves this header in the response.
            response.headers.delete('content-encoding');
            this.addReadyResponse({
                requestId,
                response: new EdgeFunctionResponse_1.default({
                    statusCode: response.status,
                    statusMessage: response.statusText,
                    body,
                    headers: response.headers.raw(),
                }),
            });
        })
            .catch(error => {
            --this.outstandingFetchesCount;
            this.addReadyResponse({
                requestId,
                error,
            });
        });
    }
    addReadyResponse(response) {
        this.readyResponses.push(response);
        this.sendNextReadyResponse();
    }
    async sendNextReadyResponse() {
        // If the worker is waiting, it means it's ready to receive the next response
        // in the shared buffer. This ensures that we don't overwrite the data in the
        // shared buffer before the worker has finished with it.
        if (this.workerIsWaiting) {
            const readyResponse = this.readyResponses.shift();
            this.copyDataToExchangeBuffer(readyResponse);
            this.wakeWorker();
        }
    }
    copyDataToExchangeBuffer(data) {
        (0, assert_1.default)(data);
        // TODO: If the buffer is too large, grow it?
        // TODO: In this case the new buffer would have to be sent to the worker.
        const serializedData = Serializer_1.Serializer.serialize(data);
        // First set the length of the serialized data.
        this.dataLength[0] = serializedData.byteLength;
        // Copy the data into the exchange buffer.
        serializedData.copy(buffer_1.Buffer.from(this.exchangeBuffer));
    }
    /// Wakes the worker that has been synchronously waiting for the next ready response.
    /// For why this is required, read EdgeFunctionWorker.
    wakeWorker() {
        (0, assert_1.default)(this.workerIsWaiting);
        this.workerIsWaiting = false;
        Atomics.store(this.semaphore, 0, 1);
        Atomics.notify(this.semaphore, 0, 1);
    }
    // Allows to replace the default fetch implementation with the mocked one.
    static setFetchImpl(fetchFunc) {
        EdgeFunctionsWorkerManager.fetchImpl = fetchFunc;
    }
}
exports.default = EdgeFunctionsWorkerManager;
EdgeFunctionsWorkerManager.fetchImpl = node_fetch_1.default;
